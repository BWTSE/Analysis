---
title: "Setup and Data preparation"
output: html_notebook
---
Load some libraries

```{r}
library(dplyr) # for dta manipulation
library(curl) # data fetching
library(ggplot2) # plotting
library(brms) # modeling
```

## Data Preparation
We begin by importing the csv data

```{r}
# d.orig <- read.csv(curl("https://raw.githubusercontent.com/BrokenWindowsInvestigation/Submissions/master/data.csv?token=AB26LHN6X2UD5NOF3RBOKI3AMGIJS"))
d.orig <- read.csv("/home/gurgy/Projects/RobotResearcher/submissions/data.csv")
head(d.orig)
```

We also define some utility functions for data processing

```{r}
# convert categories to int 1..n in the order given
encode.categorical <- function(column, categories) {
  factor(column, level = categories)
}

# convert bool to factor
encode.bool <- function(column) {
  encode.categorical(column, c("true", "false"))
}

# convert ordered categories to ordered factors in the order given
encode.orderedcategorical <- function(column, categories) {
  as.ordered(encode.categorical(column, categories))
}

# Change likert scales to ordered factors
encode.likert <- function(column) {
  encode.orderedcategorical(column, c(-3, -2, -1, 0, 1, 2, 3))
}
```

We use the utility function to set the correct types for each data column and list the columns for manual inspection

```{r}
d <- data.frame(
  session                       = factor(d.orig$session), 
  
  time                          = d.orig$time,
  reused_logic_constructor      = encode.bool(d.orig$reused_logic_constructor),
  reused_logic_validation       = encode.bool(d.orig$reused_logic_validation),
  reused_logic_equals           = encode.bool(d.orig$reused_logic_equals),
  reused_logic_hashcode         = encode.bool(d.orig$reused_logic_hashcode),
  has_equals                    = encode.bool(d.orig$has_equals),
  has_hashcode                  = encode.bool(d.orig$has_hashcode),
  
  documentation                 = encode.orderedcategorical(d.orig$documentation, c("Incorrect", "None", "Correct")),
  
  var_names_copied_all          = d.orig$var_names_copied_all,
  var_names_copied_good         = d.orig$var_names_copied_good,
  var_names_copied_good.ratio   = d.orig$var_names_copied_good / d.orig$var_names_copied_all,
  var_names_new_all             = d.orig$var_names_new_all,
  var_names_new_good            = d.orig$var_names_new_good,
  var_names_new_good.ratio      = d.orig$var_names_new_good / d.orig$var_names_new_all,
  var_names_edited_all          = d.orig$var_names_edited_all,
  var_names_edited_good         = d.orig$var_names_edited_good,
  var_names_edited_good.ratio   = d.orig$var_names_edited_good / d.orig$var_names_edited_all,
  sonarqube_issues              = d.orig$sonarqube_issues,
  
  group                         = factor(d.orig$group),
  education_level               = encode.orderedcategorical(d.orig$education_level, c("None", "Some bachelor studies", "Bachelor degree", "Some master studies", "Master degree", "Some Ph.D. studies", "Ph. D.")),
  education_field               = factor(d.orig$education_field),
  work_domain                   = factor(d.orig$work_domain),
  
  work_experience_programming   = d.orig$work_experience_programming,
  work_experience_java          = d.orig$work_experience_java,
  
  workplace_pair_programming    = encode.bool(d.orig$workplace_pair_programming),
  workplace_peer_review         = encode.bool(d.orig$workplace_peer_review),
  workplace_td_tracking         = encode.bool(d.orig$workplace_td_tracking),
  workplace_coding_standards    = encode.bool(d.orig$workplace_coding_standards),
  
  task_completion               = encode.orderedcategorical(d.orig$task_completion, c("Not submitted", "Does not compile", "Invalid solution", "Completed")),
  
  quality_pre_task              = encode.likert(d.orig$quality_pre_task),
  quality_post_task             = encode.likert(d.orig$quality_post_task),

  modified_lines                = d.orig$modified_lines,
  
  high_debt_version             = encode.bool(d.orig$high_debt_version),
  
  scenario                      = encode.categorical(d.orig$scenario, c("booking", "tickets")),
  
  order                         = encode.orderedcategorical(d.orig$order, c(0, 1)),
  large_structure_change        = encode.bool(d.orig$large_structure_change)
)

str(d)
```

Pick out some subdata sets
```{r}
d.sessions <- d %>% group_by(session) %>% summarise(
  across(task_completion, min),
  across(c(
    education_level, 
    education_field, 
    work_domain, 
    group,
    work_experience_java, 
    work_experience_programming, 
    workplace_coding_standards, 
    workplace_pair_programming, 
    workplace_peer_review, 
    workplace_td_tracking
  ), first)
  ) 

d.sessions.completed <- d.sessions %>% filter(task_completion == "Completed")
d.only_submitted <- d %>% filter(task_completion != "Not submitted")

d.only_submitted$sonarqube_issues.s = scale(d.only_submitted$sonarqube_issues)
d.only_submitted$work_experience_programming.s = scale(d.only_submitted$work_experience_programming)
d.only_submitted$work_experience_java.s = scale(d.only_submitted$work_experience_java)
```




